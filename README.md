# GEM Polaris ECE 484 Team Kachow

⚠️ Disclaimer: No one can actually run this locally unless you have access to a UIUC ubuntu machine in the ECE 484 classroom. This README file rather shows the results of our project. 

## Abstract

This is a project in which we test out a pipeline which we run using ROS on a GEM Polaris Vehicle. This pipeline includes step-by-step processing of ROS subscriber images generated by ZED2 Camera output to publishing steering angle. This also includes algorithms on how we publish acceleration values and how we maneuver through complex environments such as rainy and snowy conditions.

## Pipeline
### ① Steering
Below shows an image of the pipeline we use to processing our ZED2 Camera output. Once processed, we calculate an approximate steering angle for which the car should turn. 

<p align="center">
  <img src="https://github.com/user-attachments/assets/0b335561-5c45-45ab-98ec-646e10a44860" alt="drawing" width="600"/>
</p>

#### Ⓐ Bilateral Filter
The Bilateral Filter acts just like a gaussian filter which is neat for testing in various environmental conditions. Each pixel in the image recieved from the ZED2 camera will utilize neighboring pixels to estimate what the its new pixel value should be, which in turn blurs the image. Any snow or rain droplets that faces the camera will average itself out and blend with the image.

#### Ⓑ YoloPV2

The blurred output of the Bilateral Filter is then sent into a YoloPV2 model which performs pedestrian and lane detection. Below shows an example output image of the YoloPV2 model which we captured. Note that the image is blurred which was the results of the previous bilateral filter.

<p align="center">
  <img src="https://github.com/user-attachments/assets/5047e8aa-7db9-4849-8b52-eca8ccda0209" alt="drawing" width="45%"/>
</p>

We outsourced the YoloPV2 model from [here](https://github.com/CAIC-AD/YOLOPv2)

#### Ⓒ Color Gradient Thresholding

With the output of the YoloPV2 model, we needed to extract the lanes itself which are marked in red. Therefore, we can filter for red colors using HLS Color Thresholding. Its not enough to filter for Red since the output is transparent and we can see the lanes itself below the red markings as depicted in the YoloPV2 output. I also want to mention that we turned off gradient filtering. Gradient filtering compares 2 pixels side by side to measure a change in the pixel value. If there is high pixel difference, the pixel will be marked. However, we found out that the gradient thresholding did very little to improve the output, so to increase performance, we did not run the gradient thresholding function. The implementation, however, is still within the repository. After performing the thresholding, we produced output image such as below.  

<p align="center">
  <img src="https://github.com/user-attachments/assets/3043d006-36c7-4ac2-8220-9149ca77c0ad" alt="drawing" width="45%"/>
</p>

#### Ⓓ Perspective Transform

With the output of the color thresholding, we can transform our view to help determine our steering angle. In order to do so, we have to undertand how perspectives work. If we look at a straight road, the road itself will look like a trapezoid where the top right corner of the road will be closer to the top left corner of the road compared to the bottom right and bottom left. Therefore, we designed to create our own trapezoid and place it on a the outer lane as shown on the left image below. We then took all of the contents within the trapezoid, and created a 2d top-down view as shown in the image to the right. With this new image, we can determine whether the road is turning left or right.

<p align="center">
  <img src="https://github.com/user-attachments/assets/2695730b-7837-4f91-b42a-477ecd6ae1a1" width="45%" />
  <img src="https://github.com/user-attachments/assets/0fd3ce67-bdd3-445f-add5-7a558ebdc0eb" width="46%" />
</p>


#### Ⓔ Steering Angle

<p align="center">
  <img src="https://github.com/user-attachments/assets/4a8ed2a7-d170-43e9-8d80-8c757dab680a" alt="drawing" width="45%"/>
</p>

### ② Pedestrian Detection

Utilizing the output 

### ③ Decision Tree
The entirety of the algorithm can be summarized into a single decision tree. 

## Results

